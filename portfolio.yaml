name: Jake Pullen
label: Senior Data Engineer
contact:
  email: hello@jake-is.me
  location: Kettering, Northampton, England
summary:
- 'Transformational Senior Data Engineer: Driving Business Growth through Data-Driven
  Insights'
- Results-driven professional with a proven track record of tackling complex data
  challenges across multiple industries.
- With a passion for harnessing the power of data to inform strategic decision-making,
  I deliver actionable insights that drive business growth and unlock hidden opportunities.
- Skilled in designing and implementing scalable data architectures, I excel at collaborating
  with cross-functional teams to bridge gaps between data science, business strategy,
  and technical execution.
image_path: img/main_photo.jpg
skills:
- name: Python, SQL, PySpark, Databases
  proficiency: 100
  proficiency_label: Expert
- name: Azure, DevOps, GIT, Azure Data Factory, AI Engineering,
    Linux, APIs, MCPs
  proficiency: 80
  proficiency_label: Advanced
- name: NoSQL, DAX, Web Development, Rust
  proficiency: 60
  proficiency_label: Clear understanding
social_links:
- label: Jake - LinkedIn
  svg_path: img/linkedin.svg
  url: https://www.linkedin.com/in/jake-pullen/
- label: Jake - GitHub
  svg_path: img/github.svg
  url: https://github.com/Jake-Pullen
- label: Jake - Blog
  svg_path: img/globe.svg
  url: /blog
base_url: 127.0.0.1:5500
projects:
- title: Devin
  highlights:
  - At home AI Agent, powered all locally with the option to use online LLMs
  - MCP Understanding, Tool building and using
  - Constantly growing tool base to be more helpful
  summary: My own custom "Jarvis" from Iron Man, able to look for folders on my pc, tell me the weather for any location and control my Phillips Hue Lights. With plans to add more automations in time.
  url: https://github.com/Jake-Pullen/devin/
- title: Various Ad-hoc Coding Projects
  highlights:
  - Motivated by a passion for self-improvement, these projects push me to explore
    new programming paradigms and tools at my own pace.
  - Regularly working on diverse tasks increases my learning speed and adaptability
    across different domains and languages.
  - Each project is an opportunity to apply best practices such as clean code principles,
    testing, and version control to reinforce good habits.
  - Encourages experimentation with emerging libraries and frameworks, leading to
    deeper understanding of software design and architecture.
  summary: A collection of personal projects aimed at improving my Python and Rust
    skills through hands-on experimentation and continuous learning. These projects
    are driven by curiosity and the desire to explore new technologies, solve real-world
    problems, and strengthen technical capabilities.
  url: https://github.com/Jake-Pullen
- title: Data Pipeline for YNAB
  highlights:
  - 'Improved data handling: This application effectively detects and resolves duplicated
    data and lost data, reducing unnecessary data transfer and improving load times
    through its delta-style approach.'
  - 'Accelerated processing: leveraging Rust-built Polars for rapid data processing,
    and minimizing file sizes with Parquet storage for efficient data transfer.'
  - 'Enhanced transparency: integrated documentation empowers users to quickly understand
    and debug the application''s inner workings, while self-documenting code ensures
    ease of maintenance and updates.'
  summary: I designed and developed a robust data ingestion application, adhering
    to industry best practices in ETL and Medallion architecture, with a focus on
    seamless scalability, reliability, and maintainability. The application features
    comprehensive error handling, logging, unit testing, and proper exit codes, ensuring
    fast and reliable debugging capabilities, all while leveraging optimal tools such
    as Polars, YAML, and Parquet files.
  url: https://github.com/Jake-Pullen/data_pipeline_for_YNAB/
- title: Advent of Code
  highlights:
  - Developed expertise in Python, leveraging its strengths for efficient coding and
    problem-solving.
  - Refined my ability to break down complex problems into manageable parts, and learned
    to adapt to unexpected inputs and edge cases.
  - Improved code organization, readability, and maintainability through careful planning,
    commenting, and testing.
  - Gained a deeper understanding of fundamental algorithms and data structures, including
    sorting, searching, graph traversal, and dynamic programming techniques.
  - Developed skills in coding best practices, debugging, and version control (Git),
    ensuring reliable and efficient code deployment.
  - Demonstrated proficiency with various data structures (e.g., arrays, lists, dictionaries)
    and their applications in solving computational problems.
  - Revisited and reinforced core computer science concepts, including data types,
    object-oriented programming, recursion, and functional programming.
  summary: Embracing the Advent of Code challenge as an opportunity for growth, I
    dedicate myself to annually tackle this coding puzzle contest. Through every iteration,
    I strive to enhance my problem-solving skills, expand my technical knowledge,
    and cultivate a deeper understanding of computer science concepts.
  url: https://github.com/Jake-Pullen/advent_of_code
work_experience:
- company: Aiimi
  position: Senior Consultant Data Engineer
  start_date: May 2024
  end_date: Present
  summary: As a trusted data engineer, I leverage my expertise to design, develop,
    and optimize data systems that unlock valuable insights for businesses. My primary
    focus is on transforming raw data into actionable intelligence, driving informed
    decision-making and business growth. By delivering high-quality data solutions,
    I help clients stay ahead in their industry.
  url: https://www.aiimi.com/
  highlights:
  - I am a co-leader of the Data Community of Practice, facilitating an enviroment
    where any data professional feels empowered to share experiences, knowledge and
    recent achievements.
  - I design, develop, and maintain scalable data products that integrate various
    data models and datasets, delivering actionable insights to drive business decisions.
  - I developed a comprehensive data validation framework, empowering teams to create
    robust and repeatable tests, ensuring data quality and confidence in their data
    pipelines.
  - I built an automated documentation tool that generates detailed documentation
    for complex data models, including markdown files and interactive mermaid diagrams
    for visualizing lineage, impact analysis, and entity relationships.
- company: The Access Group
  position: Data Engineer
  start_date: April 2021
  end_date: May 2024
  summary: As the primary data engineer for finance in the healthcare sector, I played
    a critical role in driving financial reporting, forecasting, and invoice generation.
    Additionally, I led complex patient data migrations to support onboarding new
    clients and maintained the integrity of our data warehouse reporting layer.
  highlights:
  - I developed and maintained a comprehensive financial forecasting tool that Integrated
    Care Boards (ICB) used to report to the NHS England
  - I led patient data migration efforts for new clients, guaranteeing accurate and
    timely importation of vital patient information into our systems.
  - I created a secure data deletion solution that ensured GDPR compliance by removing
    client data from our multi-client database. The application logged all deletions
    and operated within specified timeframes to balance data erasure with system performance.
  - I enhanced the existing invoice generation system, significantly reducing error
    rates and incorporating advanced debugging capabilities for faster troubleshooting.
  url: https://www.theaccessgroup.com/
- company: CDW
  position: Service Desk Analyst
  start_date: July 2020
  end_date: April 2021
  summary: Serve as the primary point of contact for technical support issues across
    a diverse portfolio of clients. Manage and facilitate access to secure Data Centre
    facilities, ensuring efficient resolution of technical queries.
  highlights:
  - Successfully interacted with second and third-line teams, on-site engineers, and
    end-users to provide timely and effective support, ensuring seamless resolution
    of technical issues and maintaining strong relationships with key stakeholders.
  - Consistently met or exceeded Service Level Agreement (SLA) targets, demonstrating
    a commitment to delivering exceptional customer service while minimizing downtime
    and maximizing productivity for our clients.
  - Effectively bridged the gap between technical and non-technical language, translating
    complex technical concepts into clear, concise explanations that end-users could
    understand, ensuring effective support and resolution of issues in a rapidly changing
    technical environment.
  url: https://www.uk.cdw.com/
interests:
- name: Coding
  summary:
  - As a Data Engineer, I believe that continuous learning and improvement are essential
    to staying ahead in the industry. Outside of work, I dedicate time to coding as
    a hobby to maintain and expand my skills. By doing so, I'm able to keep my knowledge
    up-to-date with the latest trends, technologies, and best practices. This not
    only enhances my professional abilities but also enables me to tackle complex
    problems more efficiently and creatively.
  - Moreover, coding as a hobby allows me to explore new areas of interest, experiment
    with innovative solutions, and develop a deeper understanding of software development
    principles. By doing so, I'm able to bring fresh perspectives and ideas back into
    the workplace, driving innovation and improvement in my projects.
- name: Logistical puzzle and simulation games
  summary:
  - As a Data Engineer, I enjoy playing logistical puzzle and simulation games in
    my free time because they align with my skills and interests. These types of games
    challenge me to optimize routes, manage resources, and make data-driven decisions
    - all skills that are highly relevant to my work as a Data Engineer.
  - Playing these games also helps me develop problem-solving skills under pressure,
    think critically, and analyze complex systems. Additionally, I'm able to apply
    mathematical concepts such as linear programming, dynamic programming, and graph
    theory to solve puzzles and optimize game outcomes.
  - Moreover, these games provide an opportunity for me to work with large datasets,
    test different scenarios, and explore the impact of various factors on system
    performance. This hands-on experience helps me develop a deeper understanding
    of how data drives decision-making in complex systems - a valuable skillset for
    any Data Engineer.
